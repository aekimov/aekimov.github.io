<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://aekimov.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://aekimov.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-08-08T17:34:44+00:00</updated><id>https://aekimov.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">How to Fine-Tune LLMs Without Being an AI Expert</title><link href="https://aekimov.github.io/blog/2024/how-to-fine-tune-llms-without-being-an-ai-expert/" rel="alternate" type="text/html" title="How to Fine-Tune LLMs Without Being an AI Expert"/><published>2024-11-05T17:50:22+00:00</published><updated>2024-11-05T17:50:22+00:00</updated><id>https://aekimov.github.io/blog/2024/how-to-fine-tune-llms-without-being-an-ai-expert</id><content type="html" xml:base="https://aekimov.github.io/blog/2024/how-to-fine-tune-llms-without-being-an-ai-expert/"><![CDATA[<h4>This guide will show you how to use LLaMA-Factory to fine-tune language models tailored to your specific needs.</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*caJp31As5lOXaj3JNjfFGA.jpeg"/><figcaption>Generated by ChatGPT</figcaption></figure> <p>Fine-tuning large language models (LLMs) has become more accessible than ever. You don’t need powerful computers or deep expertise in Machine Learning and Natural Language Processing anymore. You can customize these advanced models for your specific tasks — a capability that used to be reserved for big corporations.</p> <p>We will dive in and explore how to fine-tune models and generate responses using them.</p> <h4>What is Fine-Tuning?</h4> <p><strong>Fine-tuning</strong> is the process of taking a pre-trained language model and adapting it to perform better on a specific task or within a particular domain. Pre-trained models like GPT-4 or LLaMA have been trained on extensive datasets containing diverse text from the internet. To train those models is very demanding and difficult task to implement. While they possess a broad understanding of language, they may not excel at specialized tasks out of the box.</p> <p>Imagine you have documentation <strong>specific to your company or product</strong>, and you want to develop a chatbot that can answer users’ questions based on this information. Typically, the pre-trained model doesn’t contain any data related to your company or product. By fine-tuning the model on a smaller, task-specific dataset — such as your own documentation — you enable it to adjust its internal representations to better capture the nuances and requirements of your task. This process slightly updates the model’s weights, allowing it to generate more accurate and relevant responses tailored to your application.</p> <h4>Techniques</h4> <p>It’s important to have a basic understanding of these fine-tuning methods, even if we don’t explore all the technical details. While the underlying concepts can be complex, grasping the general ideas behind techniques like <a href="https://arxiv.org/pdf/2106.09685"><strong>LoRA</strong></a> and <a href="https://arxiv.org/pdf/2305.14314"><strong>QLoRA</strong></a> is beneficial. Although the academic papers can be challenging to read, we can simplify these techniques as follows:</p> <ul><li><strong>LoRA</strong> adds small, low-rank matrices — called adapters — to each layer of the pre-trained model. These adapters contain additional information that enhances the model’s capabilities for our needs without significantly altering the original weights.</li><li><strong>QLoRA</strong> starts by compressing a large, pre-trained model through quantization, which reduces the precision of the model’s weights (for example, from 16-bit to 4-bit). This compression drastically decreases memory usage. After quantization, the model is fine-tuned using LoRA adapters. Essentially, QLoRA combines quantization and LoRA to enable efficient fine-tuning of large models on hardware with limited resources.</li></ul> <h4>Tools</h4> <p><a href="https://github.com/hiyouga/LLaMA-Factory">LLaMA-Factory</a> offers a flexible solution for customizing the fine-tuning process of over 100 LLMs and abstracts much of the underlying complexity.</p> <p>Before any installations, I recommend using virtual environments for the installations, it would make your life easier:</p> <pre>conda create -n lfenv python=3.9<br />conda activate lfenv</pre> <p>The installation process is very simple:</p> <pre>git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git<br />cd LLaMA-Factory<br />pip install -e &quot;.[torch,metrics]&quot;</pre> <blockquote><em>If you encounter any errors, please visit the GitHub page for detailed explanations and package version requirements.</em></blockquote> <p>Also you need to install <a href="https://huggingface.co/docs/transformers/installation">transformers</a> library from <a href="https://huggingface.co/">Hugging Face</a> as well as to register an account with an <a href="https://huggingface.co/settings/tokens">access token</a>. It will allow you to download models. The easiest way to authenticate is to save the token on your machine. You can do that from the terminal using the command:</p> <pre>huggingface-cli login</pre> <p>Additionally, for instance, when accessing models from Meta, you are required to provide your contact information by filling out a form after clicking <strong>“<em>Expand to review and access”</em></strong>.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*9Y1SndR9BxfJgCHlZ3tagA.png"/></figure> <blockquote><strong><em>Important Note:</em></strong><em> Access to the model is not granted immediately, you will receive an email once the verification process is completed.</em></blockquote> <h4>Dataset Preparation</h4> <p>Here are some important points regarding the dataset preparation process. For custom dataset preparation:</p> <blockquote>The <em>dataset_info.json</em> file contains all the available datasets. If you are using a custom dataset, ensure that you include a description of the dataset in <em>dataset_info.json</em> and specify <em>dataset: dataset_name</em> before initiating training.</blockquote> <p>For our tests, we will be using the predefined alpaca_en_demo dataset, which is already included and referenced in dataset_info.json.</p> <h4>Fine-tuning</h4> <p>Starting with a brief overview of the web interface can be helpful, as it allows you to easily see and adjust various parameters. To access it:</p> <pre># We explicitly specify what GPU we are going to use.<br />set CUDA_VISIBLE_DEVICES=0 </pre> <pre>cd LLaMA-Factory<br />python src/webui.py</pre> <p>Once you do this, the web page will be opened:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*wWdsQFIBpD0g2Hy6-5AC6Q.png"/><figcaption>Web UI view</figcaption></figure> <p>We won’t dive into the specifics of each parameter at this time — that’s a topic for another discussion. The key steps here involve choosing a model, a fine-tuning method, and a dataset. I selected the Llama-3–3B model, the Lora fine-tuning, and the alpaca_en_demo dataset. By default, the model will be saved in the LLaMA-Factory/save folder. For now, we can leave the other parameters as they are.</p> <p>When you press Start the training will begin. When training is finished you can access the files and inspect them.</p> <p>There is another way to configure and train without web interface. You can specify the configuration .yaml file. As an example you can reuse the one that we just generated training_args.yaml and place it in LLaMA-Factory folder. Also you can inspect predefined configs in example folder by Llama-Factory creators.</p> <p>The config that I used, I changed the folder, where it will be saved, num_train_epochs to make trainig faster just for testing purposes and some logging settings of training and validation loss. Feel free to try any parameters that you like.</p> <p>When you press Start, the training process will begin. Once the training is complete, you can access and review the generated files.</p> <p><strong>Alternatively</strong>, you can configure and train without using the web interface by specifying a .yaml configuration file. For instance, you can use the training_args.yaml file that was just generated and place it in the LLaMA-Factory folder. Additionally, you can explore the predefined configurations provided by the LLaMA-Factory creators in the example folder.</p> <p>In my new configuration, I adjusted the output folder location and changed some logging settings for training and validation loss. Feel free to experiment with any parameters you wish.</p> <pre>bf16: true<br />cutoff_len: 1024<br />dataset: alpaca_en_demo<br />dataset_dir: data<br />ddp_timeout: 180000000<br />do_train: true<br />eval_steps: 10<br />eval_strategy: steps<br />finetuning_type: lora<br />flash_attn: auto<br />gradient_accumulation_steps: 8<br />include_num_input_tokens_seen: true<br />learning_rate: 5.0e-05<br />logging_steps: 1<br />lora_alpha: 16<br />lora_dropout: 0<br />lora_rank: 8<br />lora_target: all<br />lr_scheduler_type: cosine<br />max_grad_norm: 1.0<br />max_samples: 100000<br />model_name_or_path: meta-llama/Meta-Llama-3-8B<br />num_train_epochs: 3.0<br />optim: adamw_torch<br />output_dir: saves\Llama-3-8B\lora\train<br />packing: false<br />per_device_eval_batch_size: 2<br />per_device_train_batch_size: 2<br />plot_loss: true<br />preprocessing_num_workers: 16<br />report_to: none<br />save_steps: 100<br />stage: sft<br />template: default<br />val_size: 0.1<br />warmup_steps: 0</pre> <p>To start training:</p> <pre># We explicitly specify what GPU we are going to use.<br />set CUDA_VISIBLE_DEVICES=0 <br />llamafactory-cli train training_args.yaml</pre> <h4>Response Generation</h4> <p>After obtaining our fine-tuned model, we can generate responses using it. This code demonstrates how to load a pre-trained Llama-3–8B model and its tokenizer, apply the fine-tuned weights, and generate a text response based on a provided prompt. The generated text is then decoded and printed.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/10c0e06ad7662a9cd083fb9a21108ffa/href">https://medium.com/media/10c0e06ad7662a9cd083fb9a21108ffa/href</a></iframe> <p>If you want to see how the model responds without fine-tuning, you can comment out this line:</p> <pre>model = PeftModel.from_pretrained(model, ft_model_path)</pre> <p>Thanks for reading this article! I hope it gave you a helpful introduction to fine-tuning and how to generate responses. I wanted to keep it simple and let you try it out without diving too deep into technical details. Feel free to leave a comment or ask any questions you have.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=874be25002e2" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://levelup.gitconnected.com/how-to-fine-tune-llms-without-being-an-ai-expert-874be25002e2">How to Fine-Tune LLMs Without Being an AI Expert</a> was originally published in <a href="https://levelup.gitconnected.com">Level Up Coding</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Mastering Table/Collection View DiffableDataSource: A Comprehensive Guide</title><link href="https://aekimov.github.io/blog/2023/mastering-tablecollection-view-diffabledatasource-a-comprehensive-guide/" rel="alternate" type="text/html" title="Mastering Table/Collection View DiffableDataSource: A Comprehensive Guide"/><published>2023-03-26T18:19:41+00:00</published><updated>2023-03-26T18:19:41+00:00</updated><id>https://aekimov.github.io/blog/2023/mastering-tablecollection-view-diffabledatasource-a-comprehensive-guide</id><content type="html" xml:base="https://aekimov.github.io/blog/2023/mastering-tablecollection-view-diffabledatasource-a-comprehensive-guide/"><![CDATA[<h3>Mastering Table/Collection DiffableDataSource: A Comprehensive Guide</h3> <h4>This tutorial will demonstrate the process of refactoring and implementing DiffableDataSource in UITableView or UICollectionView.</h4> <p>This article is a follow-up to the previous <a href="https://medium.com/itnext/handling-multiple-requests-using-combine-in-swift-8e19e5c4fa52">one</a>.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*wyN-2smaYNMUvrL_4umICA.jpeg"/><figcaption>Picture from <a href="https://www.flaticon.com/free-icon/menu_438886">Flaticon</a> by <a href="https://www.flaticon.com/authors/dinosoftlabs">DinosoftLabs</a></figcaption></figure> <h4>Summary</h4> <p>Currently, when we refresh a table view, all the cells get reloaded. This is acceptable in the present scenario as we anticipate receiving new data (a random number of jokes each time). However, let’s assume we have a feed of posts that infrequently updates, and reloading the entire table view each time results in unnecessary work. Another example would be when implementing pagination, where we add new items and then reload the entire table view, rather than just displaying the new items. We could achieve this without reloading all cells by using reloadRows(at: with:) or reloadItems(at:), but it would require additional calculations to provide accurate indexPaths. In such cases, using UITableViewDiffableDataSource can help us resolve these issues by managing all the complex operations and updating only the necessary changes in an efficient manner.</p> <p>The concept is to substitute the previous data source methods with UITableViewDiffableDataSource. Additionally, we had been manually refreshing the table view using the didSet property observation.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/0ce11b20c8deaed4d5b29c0980a6e6b1/href">https://medium.com/media/0ce11b20c8deaed4d5b29c0980a6e6b1/href</a></iframe> <h4><strong>DiffableDataSource</strong></h4> <p>This is the object you use to manage data and provide cells for a table view.</p> <p>A <em>diffable data source</em> object is a specialized type of data source that works together with your table view object. It provides the behavior you need to manage updates to your table view’s data and UI in a simple, efficient way. It also conforms to the UITableViewDataSource protocol and provides implementations for all of the protocol’s methods.</p> <p>To connect a diffable data source to a table view, you create the diffable data source using its init(tableView:cellProvider:)initializer, passing in the table view you want to associate with that data source. You also pass in a cell provider, where you configure each of your cells to determine how to display your data in the UI.</p> <h4>Implementation</h4> <p>1. Create diffable data source and implement a cell provider to configure your table view’s cells.</p> <p>Within the angle brackets, we must indicate the section type as Int, and the model type as Joke, which must conform to the Hashable protocol.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/b2afef33c349a5551da67b7bfc84687d/href">https://medium.com/media/b2afef33c349a5551da67b7bfc84687d/href</a></iframe> <p>2. Generate the current state of the data.</p> <p>Basically this is the code that we had in tableView(_:cellForRowAt:)</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/dd4532e70c7b91701895213f9e005294/href">https://medium.com/media/dd4532e70c7b91701895213f9e005294/href</a></iframe> <p>3. Display the data in the UI.</p> <p>We generate the current state of the data and display the data in the UI by constructing and applying a snapshot. Also in updateJokes we updating the snapshot with new items. This way we can get rid of jokes property array that we set before.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/56dc713d144a1df639842bd8282306d9/href">https://medium.com/media/56dc713d144a1df639842bd8282306d9/href</a></iframe> <p>4. <strong>Don’f forget </strong>to connect a diffable data source to your table view.</p> <pre>tableView.dataSource = dataSource</pre> <h4>iOS 15 Update</h4> <p>Apple changed the behavior of the method apply(_:animatingDifferences:) of the UITableViewDiffableDataSource and UICollectionViewDiffableDataSource classes.</p> <p>On iOS 14 and before, calling apply(snapshot, animatingDifferences: false) was equivalent to calling reloadData. And calling apply(snapshot, animatingDifferences: true) would perform a diff on the data source and only update cells that the data changed.</p> <p>As of iOS 15, applying a snapshot using this API will <strong>always</strong> perform a diff, optionally animate the UI updates based on the value of animatingDifferences.</p> <p>To explicitly reload the whole table/collection without diffing, you can now call applySnapshotUsingReloadData(_:completion:) instead.</p> <p>Please bear in mind the distinction and select the methods that are appropriate for your requirements.</p> <p>The project is available on <a href="https://github.com/aekimov/CombineMultipleRequests">GitHub</a>.</p> <p>Thank you for taking the time to read this article. I hope it has been beneficial for you. Feel free to leave a comment or ask any questions you may have.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4a0fe5f323de" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://itnext.io/mastering-table-collection-view-diffabledatasource-a-comprehensive-guide-4a0fe5f323de">Mastering Table/Collection View DiffableDataSource: A Comprehensive Guide</a> was originally published in <a href="https://itnext.io">ITNEXT</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Handling Multiple Requests Using Combine in Swift</title><link href="https://aekimov.github.io/blog/2023/handling-multiple-requests-using-combine-in-swift/" rel="alternate" type="text/html" title="Handling Multiple Requests Using Combine in Swift"/><published>2023-03-16T11:28:03+00:00</published><updated>2023-03-16T11:28:03+00:00</updated><id>https://aekimov.github.io/blog/2023/handling-multiple-requests-using-combine-in-swift</id><content type="html" xml:base="https://aekimov.github.io/blog/2023/handling-multiple-requests-using-combine-in-swift/"><![CDATA[<h4>This tutorial will demonstrate the usage of Combine for handling networking tasks.</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*4-VIloWfBF6RKjiWU9mwsg.jpeg"/><figcaption>Picture from <a href="https://www.freepik.com/author/stories">Storyset</a> on <a href="https://www.freepik.com/free-vector/setup-wizard-concept-illustration_7140756.htm#query=sequence%20request&amp;position=1&amp;from_view=search&amp;track=ais">Freepik</a></figcaption></figure> <h4><strong>Introduction</strong></h4> <p>Most likely, all of us have encountered situations where we’ve had to write code like this:</p> <pre>photoManager.getAccess { accessResult in<br />    switch accessResult {<br />    case .success:<br />        photoManager.selectPhoto { selectionResult in<br />            switch selectionResult {<br />            case .success:<br />                photoManager.uploadPhoto { uploadResult in<br />                    ...<br />                }<br />            case .failure: <br />                ...<br />            }<br />        }<br /><br />    case failure:<br />        photoManager.showAlert {<br />            photoManager.retry {<br />                ...<br />            }<br />        }<br />    }<br />}</pre> <p>This is commonly referred to as the <a href="https://en.wikipedia.org/wiki/Pyramid_of_doom_(programming)">Pyramid of Doom</a> — a code structure that resembles an arrowhead and is considered an anti-pattern resulting from multiple nested closures or structures such as nested conditions or switch statements.</p> <p>In this material, we will explore how to eliminate nested closures using Combine and thus simplify the code while enhancing its readability and maintainability. Let’s explore how it can be valuable for handling asynchronous tasks, such as networking.</p> <h4>API</h4> <p>As an example, I will be using the <a href="https://api.chucknorris.io/">chucknorris.io</a><strong> </strong>API, which provides hand-curated Chuck Norris facts. After all, who doesn’t enjoy Chuck Norris facts? 😎</p> <p>API method to retrieve a list of available categories:</p> <pre>https://api.chucknorris.io/jokes/categories</pre> <p>API method to retrieve a random joke from a given category:</p> <pre>https://api.chucknorris.io/jokes/random?category={category}</pre> <p>To get the jokes, we need to load the possible categories (an array of strings) and then make another request to get the joke for a particular category. We have a chain of requests that go one after the other.</p> <h4>Start Project</h4> <p>Firstly, let’s take a quick look at the initial project I created. You can find it on <a href="https://github.com/aekimov/CombineMultipleRequests">GitHub</a> with a detailed history of changes made to the code.</p> <p>It includes two models — Category and Joke — both of which have only one field of type String.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/0cc599fad6592b60f03ed75abe83ee38/href">https://medium.com/media/0cc599fad6592b60f03ed75abe83ee38/href</a></iframe> <p>There is also a UITableView with UIRefreshControl which has a target action onRefresh to trigger an update. The implementation of table view’s delegate methods moved to the extension.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/4c7fa6d2621fd8f8f56ae92507ef3ff7/href">https://medium.com/media/4c7fa6d2621fd8f8f56ae92507ef3ff7/href</a></iframe> <p>Additional helpers:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/a10617f67537d4c4ea39c92f92fab0e7/href">https://medium.com/media/a10617f67537d4c4ea39c92f92fab0e7/href</a></iframe> <p>We need to implement updateJokes to fetch data from the remote, map it and assign it to the jokes property.</p> <h4>Adding Combine Publishers</h4> <p>First, we need to load categories. I encapsulated the logic into a function loadCategories.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/86a6672aea6282d0aa910317cd396a9f/href">https://medium.com/media/86a6672aea6282d0aa910317cd396a9f/href</a></iframe> <p>Let’s take a look at what’s going on in this code.</p> <h4>DataTaskPublisher</h4> <p>Combine ships with built-in support for creating publishers based on URL/ URLRequest similar to the dataTask API that we’ve all used. We can use dataTaskPublisher method of URLSession to get a publisher that wraps a data task for a given URL.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/edbbfc014dc4b2cfec755d4755de1dcb/href">https://medium.com/media/edbbfc014dc4b2cfec755d4755de1dcb/href</a></iframe> <p>Below we seeOutput and Failure types of DataTaskPublisher</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/5b94d9fb33499656b6c20835e5f6b5a4/href">https://medium.com/media/5b94d9fb33499656b6c20835e5f6b5a4/href</a></iframe> <p>The Output type is a tuple that consists of both the data and the response. The Failure type is set to URLError .</p> <h4>TryMap</h4> <p>Since DataTaskPublisher could result with an error we need to handle it.</p> <p>tryMap takes a closure as its parameter and returns a new element. If the closure throws an error, the publisher fails with the thrown error. Here we can also check the response and the status code.</p> <h4>Decode</h4> <p>Use decode with a JSONDecoder to decode data received from a DataTaskPublisher using the Decodable protocol.</p> <h4>Map</h4> <p>Combine’s map operator performs a function similar to that of <em>map</em> in the Swift standard library: it uses a closure to transform each element it receives from the upstream publisher. You use it to transform from one kind of element to another.</p> <p>I think that the functional representation makes it easier to reason about the code.</p> <p>Next, we will load jokes that match the specified categories, starting with just one joke for now. The code implementation is almost identical, we will refactor it later..</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/2d4ec499f25e06c7f74cd2f830a70ab9/href">https://medium.com/media/2d4ec499f25e06c7f74cd2f830a70ab9/href</a></iframe> <p>Our next step is to link these methods together. Let’s create a new function where the magic happens and all these methods are chained.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/391c1151f4bf7fd63d51c5fda35570e4/href">https://medium.com/media/391c1151f4bf7fd63d51c5fda35570e4/href</a></iframe> <h4>FlatMap</h4> <p>The flatMap(maxPublishers:_:) operator transforms a <em>publisher</em> into completely <em>new publisher</em> that produces elements of the same type. It is used when you want to reach into inner publisher to get its elements.</p> <p>First we load the categories, when we finish loading the categories, flatMap will pass the result to loadJoke and execute the second request.</p> <p>The final step is to subscribe to the publisher. We can do it in the updateJokes method that we left empty.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/16b697e98177ece40c8f274088c7478b/href">https://medium.com/media/16b697e98177ece40c8f274088c7478b/href</a></iframe> <p>We use our loadData method to get the publisher. Use the receive(on:options:) operator to receive results and completion on a specific scheduler, such as performing UI work on the main run loop. This operator changes the execution context of downstream messages.</p> <p>We use sink(receiveCompletion:receiveValue:)to observe values received by the publisher and process them using a closure you specify. This method creates the subscriber.</p> <p>To hold on to the subscription we need to store it in a set of AnyCancellable.</p> <p>Run the app to see the result. We have chained two requests and retrieved one quote.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/270/1*x-RUGkSAlG-A95O45DOJgg.gif"/></figure> <p>Now we can refactor the loading functionality to the final implementation and gather it in the extension:</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/bed2f64fcc33d3d9444f2e3847dbe1b0/href">https://medium.com/media/bed2f64fcc33d3d9444f2e3847dbe1b0/href</a></iframe> <p>I’ve made the load function generic so that we can refactor loadCategories and loadJoke. Additionally, I have included a loadJokes method that enables us to download a random number of jokes, as opposed to just one as we previously had.</p> <p>We could do it with the help of MergeMany<strong> </strong>publisher which takes an array of upstream publishers and merge them. In order to get an array of jokes we need to apply count operator which emits arrays of at most count elements from an upstream publisher. If the upstream publisher finishes before collecting the specified number of elements, the publisher sends an array of only the items it received. This may be fewer than countelements.</p> <p>Note that MergeMany<strong> </strong>finishes responses of requests in a random order. Use Zip to preserve the order.</p> <p>Final result:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/270/1*nA_GCRAyTnZwDVWN8mwuZg.gif"/><figcaption>Final Result</figcaption></figure> <h4>Conclusion</h4> <p>This is a simple way to execute one or many requests in a sequence when there is a dependency between them using Combine. With Combine, we get all the abstractions like AnyPublisher for free, making the process much simpler. There’s no need to handle mutable state, semaphores, or dispatch groups doing it the old way with completion closures, and it is easy to inspect, read, and develop the code.</p> <p>You can find the final project on <a href="https://github.com/aekimov/CombineMultipleRequests">GitHub</a>.</p> <p>Thank you for taking the time to read this article. I hope you found it useful! If you have any questions or comments, please don’t hesitate to leave them below. I’m always interested in hearing your thoughts.</p> <p>In the next article, I will demonstrate how to use UITableViewDiffableDataSource to refactor UITableView.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8e19e5c4fa52" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://itnext.io/handling-multiple-requests-using-combine-in-swift-8e19e5c4fa52">Handling Multiple Requests Using Combine in Swift</a> was originally published in <a href="https://itnext.io">ITNEXT</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">How to Add Horizontal Paging with Snapping Effect in UICollectionView</title><link href="https://aekimov.github.io/blog/2023/how-to-add-horizontal-paging-with-snapping-effect-in-uicollectionview/" rel="alternate" type="text/html" title="How to Add Horizontal Paging with Snapping Effect in UICollectionView"/><published>2023-03-08T18:26:15+00:00</published><updated>2023-03-08T18:26:15+00:00</updated><id>https://aekimov.github.io/blog/2023/how-to-add-horizontal-paging-with-snapping-effect-in-uicollectionview</id><content type="html" xml:base="https://aekimov.github.io/blog/2023/how-to-add-horizontal-paging-with-snapping-effect-in-uicollectionview/"><![CDATA[<h4>Learn how to add a snapping effect and implement horizontal paging in UICollectionView with this step-by-step tutorial.</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*yNjlFr0cd-oFO90sb8TJXA.jpeg"/></figure> <p>You can find the project on <a href="https://github.com/aekimov/HorizontalPagingCollectionView">GitHub</a> with a detailed history of changes made to the code.</p> <p>Let’s say we have a horizontal collection view, the cells have a fixed height and stretch to the width of the collection view (in this example, the collection view width matches the screen width). I applied different colors to visually distinct them.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/421/1*QCM6899oDs0g7h3HkkXh3w.gif"/><figcaption>Cell Width = Scroll View Bounds Width</figcaption></figure> <p>It works just fine, but we desire a snapping paging effect when scrolling left or right. This effect is achieved by using the isPagingEnabled property of UICollectionView, which is a Boolean value that determines whether paging is enabled for the scroll view.</p> <blockquote>If the value of this property is true, the scroll view stops on multiples of the scroll view’s bounds when the user scrolls. The default value is false.</blockquote> <figure><img alt="" src="https://cdn-images-1.medium.com/max/421/1*NBgv22MGjLpgcv1SqEMXVw.gif"/><figcaption>isPagingEnabled = true</figcaption></figure> <p>If the collection view and cell widths are the same, you only need to change this property.</p> <p>However, this approach becomes ineffective as soon as we adjust the section insets or spacing between cells. Since the scroll view stops at multiples of its bounds, this can cause the cell to no longer align with it.</p> <p>Let’s modify the cell size and add spacing between them by adjusting sectionInset and minimumLineSpacing properties of the layout.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/444/1*CM0dhws-H3SlSYLuyw4d5w.gif"/><figcaption>sectionInset = UIEdgeInsets(top: 0, left: 20, bottom: 0, right: 20), minimumLineSpacing = 16</figcaption></figure> <p>My desired result is that the cells are centered and that the same number of neighboring cells are visible on both sides. There are various solutions available to achieve this, such as manually calculating the required scroll view offset based on the item size, insets, and spacing, and using the setContentOffset method of the scroll view. However, I find this approach to be somewhat cumbersome.</p> <p>Instead, we can check the start and end positions and compare the difference to a threshold. We need to add some variables for the current page, before and after the offsets, and a constant variable for the threshold. Don’t forget to switch isPagingEnabled to false or just remove it because it defaults to false.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/0df3af35b99551e4481f84b4ec8028cc/href">https://medium.com/media/0df3af35b99551e4481f84b4ec8028cc/href</a></iframe> <p>We are going to use two scroll view’s delegate methods scrollViewWillBeginDragging and scrollViewWillEndDragging.</p> <p>The approach is relatively straightforward — we set a beforeOffset in scrollViewWillBeginDragging when we start dragging and an afterOffset in scrollViewWillEndDragging when we’re about to finish. After that we calculate the difference between the two and compare it to the threshold value, while also taking into account edge cases to ensure that the index we need to scroll to exists and is within the range.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/b3d583fc3eb0ed33aaa3d74e0d09d3c9/href">https://medium.com/media/b3d583fc3eb0ed33aaa3d74e0d09d3c9/href</a></iframe> <figure><img alt="" src="https://cdn-images-1.medium.com/max/444/1*TbftUG5Us0eE60GF9BIIiA.gif"/><figcaption>Final Result</figcaption></figure> <p>This is the desired outcome. This approach can be applied to vertical collection views as well.</p> <p>I think it needs a couple of words why we needed the first line of code in scrollViewWillEndDragging</p> <pre>targetContentOffset.pointee = scrollView.contentOffset</pre> <blockquote><strong><em>targetContentOffset </em></strong>— the expected offset when the scrolling action decelerates to a stop. Your application can change the value of the targetContentOffset parameter to adjust where the scrollview finishes its scrolling animation.</blockquote> <p>If the user leaves some velocity going after lifting their finger, it can interfere with our snapping effect. To prevent this, we will implement a solution to halt any sliding effect as soon as the user lifts their finger.</p> <p>Additionally, if we want to observe any changes of the page index from the outside we could add a closure and trigger it through a didSet property observer. We can provide the previous (oldValue) page index as well.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/2b8e5cefb1b5ba55a7518743260c4c0d/href">https://medium.com/media/2b8e5cefb1b5ba55a7518743260c4c0d/href</a></iframe> <p>You can find the final project on <a href="https://github.com/aekimov/HorizontalPagingCollectionView">GitHub</a>.</p> <p>Thank you for reading this article, I hope you found it helpful! Please feel free to leave a comment or ask any questions you may have — I would love to hear your thoughts.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6295a38e49bf" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://itnext.io/how-to-add-horizontal-paging-with-snapping-effect-in-uicollectionview-6295a38e49bf">How to Add Horizontal Paging with Snapping Effect in UICollectionView</a> was originally published in <a href="https://itnext.io">ITNEXT</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry></feed>